<!DOCTYPE html>
<html lang="en" dir="ltr">

<head>
  <meta charset="utf-8">
  <title>My Site</title>
  <!-- link to CSS page -->
  <link rel="stylesheet" href="css/styles.css">
  <!-- apparently the logic is to put favicon.ico underneath css folder -->
  <link rel="shortcut icon" href="images/favicon.ico" />
  <link rel="shortcut icon" href=".ico" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Sacramento&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Montserrat&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Merriweather&display=swap" rel="stylesheet">

<title>Human Language Technologies Portfolio</title>
  </head>
  <body>
    <div class="top-container">
        <img class="top-cloud" src="images/cloud.png" alt="cloud-img" />
        <h1>Human Language Technologies Page</h1>
        <img class="bottom-cloud" src="images/cloud.png" alt="cloud-img" />
        <img src="images/mountain.png" alt="mountain-img" />
    
    <p> Welcome to the Human Language Technologies Portfolio. The portfolio includes various class projects that implement Natural Language Processing techniques. 
      <h3><a href="https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio">Link</a></h3>
    </p>
 <br>
    <h1> <a href="https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/sxj170022PortfolioAssignment0GettingStarted">Portfolio Assignment 0:Getting Started</a></h1>
    
    <p>Description: I have setup the Human Language Technologies Portfolio. This Portfolio will include a list of projects associated with NLP as well as important documentation. For this assignment, I am attaching a document called <a href= "(https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/blob/main/sxj170022PortfolioAssignment0GettingStarted/sxj170022An%20Overview%20of%20NLP.pdf)">An Overview of NLP</a></p>
    <h3><a href="https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/sxj170022PortfolioAssignment0GettingStarted">Link</a></h3>
    <br>

    <h1><a href= "https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/sxj170022PortfolioAssignment1">Portfolio Assignment 1: Text Processing with Python</a></h1>
    <p>Brief Description: (A) The purpose of the program is to process a data.csv file using Python (B) You will find An Overview of Homework 1 as well as the following code files: Homework1_sxj170022.py, homework1_config.py, and PersonClass.py. (C) All of this information in B can be found in the Homework1 folder</p>
    <h3><a href= "https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/sxj170022PortfolioAssignment1">Link</a></h3>
    <br>

    <h1><a href= "https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/sxj170022_PortfolioChapter5_GuessingGame">Portfolio Assignment: Chapter 5 Word Guessing Game</a></h1>
    <p>Brief Description: Description: The purpose of the python project is to create a guessing game from a text file. The Python Program reads in the text file anat19.txt, stores the contents of the file in a list, processes each token of the file, lemmatizes the tokens to create unique lemmas, gathers all the nouns, stores the nouns in the dictionary, and creates a guessing game based upon the 50 most common nouns in the dictionary.
        How to run: Donwload the files on eLearning and/or Github the Config file the Main Program, as well as the data folder containing anat19.txt make sure to input the following command when running: python sxj170022_PortfolioChapter5_GuessingGame.py data/anat19.txt
    </p>
    <h3><a href= "https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/sxj170022_PortfolioChapter5_GuessingGame">Link</h3>
    <br>

    <h1><a href= "https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/blob/main/sxj170022_AssignmentWordnet.ipynb">Portfolio Assignment: WordNET</a></h1>
    <p>Description: The purpose of this assignment is to experiment with WordNet and SentiWordNet. Please refer to the WordNet python file for more details</p>
      <h3><a href= "https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/blob/main/sxj170022_AssignmentWordnet.ipynb">Link</a></h3>
    <br>

    <h1>Portfolio Assignment: Chapter 8 NGrams</h1>
    <p>Description: The project involves creating unigram and bigram dictionaries for the following languages: English, French, and Italian. The purpose of the overall project is to calculate the probabilities for each language and get the overall accuracy of correctly classified instances in the test set with respect to the dictionaries. There are 2 programs for this project: Program 1 involves building languages models for the 3 languages (English, French, and Italian) and creating unigram and bigram dictionaries from these language models. The program pickles the dictionaries to save execution time in running the project. Program 2 does the following: A. It reads in the pickled dictionaries. B. Calculates the probability for each language C. Writes the language with the highest probability to a file D. Computes and outputs your accuracy as the percentage of correctly classified instances in the test set.

        Narrative: Also included is a short narrative about Ngrams.</p>
    <h3><a href="https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/sxj170022_PortfolioAssignment_NGrams">Link</a></h3>  
    <br>

    <h1><a href= "https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/sxj170022_PortfolioAssignment_WebScraper">Portfolio Assignment: Web Scraper</a></h1>
    <p>Description: This project gets a list of URLS from a starter url: <a href=https://medium.com/.>Medium Website</a>.The project scrapes through the list of URLS and outputs a text file called urls.txt. Next, text is scraped from the urls and each text is put into their own files. Since there were 51 urls in urls.txt, you should see 51 different text files containing text from each url website. Next a knowledge base is created from the texts for all the websites. Note: The knowledge base text file is very large so you may not be able to see it at a first glance on Github. A web crawler report describes the knowledge base as well as includes the top 10 terms from the knowledge and a sample dialog for the knowledge base</p>
    <h3><a href= "https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/sxj170022_PortfolioAssignment_WebScraper">Link</a></h3>
    <br>

    <h1><a href= "https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/sxj170022_Sentence%20Parsing%20Assignment">Portfolio Assignment: Sentence Parsing</a></h1>
    <p>Description: For this assignment, I created a fairly complex sentence. I drew by hand a PSG/constituency tree, a Dependency Parse and a SRL parse for the sentence. You can find the <a href="https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/blob/main/sxj170022_Sentence%20Parsing%20Assignment/sxj170022_SentenceParsingAssignment.pdf">Sentence Parsing Assignment</a> on GitHub</p>
    <h3><a href= "https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/sxj170022_Sentence%20Parsing%20Assignment">Link</a></h3>
    <br>

    <h1><a href="https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/sxj170022_Author_Attribution">Author Attribution Assignment</a></h1>
    <p>Description: For this assignment, I was tasked with performing Naive Bayes, Logistic Regression, and a Neural Network on an Author Attribution dataset. You can find the Author Attribution Assignment here.</p>
    <h3><a href="https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/sxj170022_Author_Attribution">Link</a></h3>
    <br>

    <h1><a href= "https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/sxj170022_Portfolio%20ACL%20Paper%20Summary">Portfolio Assignment ACL Summary</a></h1>
    <p>Description: For this assignment I worked with a partner, Dmitrii Obideiko on the ACL Paper Summary. We chose the DeepRapper: Neural Rap Generation where we summarize the authors' attempts at creating a DeepRapper. This summary includes the title of the paper, the author list and affiliations, a summary of the current work associated with the paper, a summary of prior works, the contributions the authors made to the paper, the evaluations authors made, the list of citations for each author and a brief conclusion about why the work was important.</p>
      <h3><a href= "https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/sxj170022_Portfolio%20ACL%20Paper%20Summary">Link</a></h3>

    <br>
    <h1><a href= "https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/Portfolio%20Chatbot">Portfolio Chatbot</a></h1>
    <p>Description: For this assignment I worked with Dmitrii Obideiko. The core functionality of the chatbot is to provide information regarding the weather in any city across the entire world (i.e. weather description, temperature, etc.). The chatbot utilizes the OpenWeatherMap API for information associated with the weather. The chatbot will ask the user to input a question to the chatbot that allows the chatbot to respond with the weather information associated with the city. For example, the user is allowed to ask a question (i.e. What's the weather in Plano? ) and the chatbot responds with 'It looks like:' followed by a weather description. There are 3 files main.py, Weatherinfo.py, and the Weather Chatbot Report</p>
    <h3><a href= "https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/Portfolio%20Chatbot">Link</a></h3>
    <br>

    <h1><a href="https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/Text%20Classification%20Assignment">Portfolio Assignment : Text Classification</a></h1>
    <p>Description: Worked with a partner to perform text classification techniques (i.e. Sequential learning via Keras and RNN) on the Women's E-Commerce Dataset. Please see the <a href="https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/blob/main/Text%20Classification%20Assignment/TextClassification.ipynb_-_Colaboratory.pdf">Text Classification Assignment</a></p>
    <h3><a href="https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/Text%20Classification%20Assignment">Link</a></h3>
  </body>
</html>
